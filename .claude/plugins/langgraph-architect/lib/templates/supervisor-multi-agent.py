"""
Supervisor Multi-Agent Template

A production-ready multi-agent system with supervisor pattern:
- Central supervisor coordinates multiple specialized agents
- Each agent has specific responsibilities
- Supervisor decides which agent to invoke
- Checkpointing for conversation memory
- Error handling and fallbacks
"""

import os
from typing import TypedDict, Annotated, Sequence, Literal
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from pydantic import BaseModel
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.sqlite import SqliteSaver


# ============================================================================
# State Definition
# ============================================================================

class SupervisorState(TypedDict):
    """
    State schema for the multi-agent supervisor system.

    Attributes:
        messages: Conversation history
        next_agent: Name of the next agent to invoke
        agent_history: Track which agents have been called
    """
    messages: Annotated[Sequence[BaseMessage], add_messages]
    next_agent: str
    agent_history: list[str]


# ============================================================================
# Agent Definitions
# ============================================================================

# Define the agents in our system
AGENTS = ["researcher", "calculator", "writer", "FINISH"]


class RouteResponse(BaseModel):
    """Response model for supervisor routing decisions."""
    next_agent: Literal["researcher", "calculator", "writer", "FINISH"]
    reasoning: str


# ============================================================================
# Tools for Agents
# ============================================================================

@tool
async def search_web(query: str) -> str:
    """
    Search the web for information.

    Args:
        query: The search query

    Returns:
        Search results
    """
    # TODO: Implement actual web search
    return f"Web search results for '{query}':\n- Result 1\n- Result 2\n- Result 3"


@tool
async def calculate(expression: str) -> float:
    """
    Evaluate a mathematical expression.

    Args:
        expression: Mathematical expression to evaluate

    Returns:
        Calculation result
    """
    try:
        # WARNING: Replace with safe math parser in production
        result = eval(expression, {"__builtins__": {}}, {})
        return float(result)
    except Exception as e:
        raise ValueError(f"Invalid expression: {e}")


@tool
async def format_document(content: str, style: str = "markdown") -> str:
    """
    Format content as a document.

    Args:
        content: Content to format
        style: Document style (markdown, html, plain)

    Returns:
        Formatted document
    """
    if style == "markdown":
        return f"# Document\n\n{content}\n\n---\n*Generated by AI Writer*"
    elif style == "html":
        return f"<html><body><h1>Document</h1><p>{content}</p></body></html>"
    else:
        return content


# ============================================================================
# Supervisor Node
# ============================================================================

async def supervisor_node(state: SupervisorState) -> SupervisorState:
    """
    The supervisor node decides which agent should act next.

    Args:
        state: Current state

    Returns:
        Updated state with next_agent selection
    """
    # Define the supervisor prompt
    system_prompt = f"""You are a supervisor managing a team of specialized AI agents.
Your team members are:
- researcher: Searches the web for information and answers factual questions
- calculator: Performs mathematical calculations and solves equations
- writer: Writes, edits, and formats documents and content

Based on the conversation, decide which agent should act next.
When the task is complete, select FINISH.

Available agents: {', '.join(AGENTS)}"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        ("system", "Based on the conversation above, who should act next? "
                   "Select one of: {agents}. "
                   "Provide your reasoning and choice.")
    ])

    # Create supervisor chain
    model = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        temperature=0
    )

    supervisor_chain = prompt | model.with_structured_output(RouteResponse)

    # Get routing decision
    try:
        response = await supervisor_chain.ainvoke({
            "messages": state["messages"],
            "agents": ", ".join(AGENTS)
        })

        # Log the decision
        decision_message = AIMessage(
            content=f"[Supervisor Decision] Routing to: {response.next_agent}\n"
                   f"Reasoning: {response.reasoning}",
            name="supervisor"
        )

        # Update agent history
        agent_history = state.get("agent_history", [])
        agent_history.append(response.next_agent)

        return {
            "next_agent": response.next_agent,
            "messages": [decision_message],
            "agent_history": agent_history
        }

    except Exception as e:
        # Fallback on error
        error_message = AIMessage(
            content=f"Supervisor error: {str(e)}. Finishing.",
            name="supervisor"
        )
        return {
            "next_agent": "FINISH",
            "messages": [error_message],
            "agent_history": state.get("agent_history", []) + ["FINISH"]
        }


# ============================================================================
# Agent Nodes
# ============================================================================

async def researcher_node(state: SupervisorState) -> SupervisorState:
    """
    The researcher agent searches for information.

    Args:
        state: Current state

    Returns:
        Updated state with research results
    """
    system_prompt = """You are a research specialist. Your job is to search for information
and provide accurate, well-sourced answers. Use the search_web tool to find information."""

    model = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        temperature=0
    ).bind_tools([search_web])

    messages = [SystemMessage(content=system_prompt)] + list(state["messages"])

    try:
        # Invoke the model
        response = await model.ainvoke(messages)

        # Execute tool calls if present
        if hasattr(response, "tool_calls") and response.tool_calls:
            # Execute tools
            tool_results = []
            for tool_call in response.tool_calls:
                if tool_call["name"] == "search_web":
                    result = await search_web.ainvoke(tool_call["args"])
                    tool_results.append(result)

            # Create final response with tool results
            final_response = AIMessage(
                content=f"Research findings:\n" + "\n".join(tool_results),
                name="researcher"
            )
        else:
            response.name = "researcher"
            final_response = response

        return {"messages": [final_response]}

    except Exception as e:
        error_message = AIMessage(
            content=f"Research error: {str(e)}",
            name="researcher"
        )
        return {"messages": [error_message]}


async def calculator_node(state: SupervisorState) -> SupervisorState:
    """
    The calculator agent performs mathematical calculations.

    Args:
        state: Current state

    Returns:
        Updated state with calculation results
    """
    system_prompt = """You are a mathematics specialist. Your job is to perform accurate
calculations and solve mathematical problems. Use the calculate tool for computations."""

    model = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        temperature=0
    ).bind_tools([calculate])

    messages = [SystemMessage(content=system_prompt)] + list(state["messages"])

    try:
        response = await model.ainvoke(messages)

        # Execute tool calls if present
        if hasattr(response, "tool_calls") and response.tool_calls:
            tool_results = []
            for tool_call in response.tool_calls:
                if tool_call["name"] == "calculate":
                    result = await calculate.ainvoke(tool_call["args"])
                    tool_results.append(f"Calculation result: {result}")

            final_response = AIMessage(
                content="\n".join(tool_results),
                name="calculator"
            )
        else:
            response.name = "calculator"
            final_response = response

        return {"messages": [final_response]}

    except Exception as e:
        error_message = AIMessage(
            content=f"Calculation error: {str(e)}",
            name="calculator"
        )
        return {"messages": [error_message]}


async def writer_node(state: SupervisorState) -> SupervisorState:
    """
    The writer agent creates and formats content.

    Args:
        state: Current state

    Returns:
        Updated state with written content
    """
    system_prompt = """You are a professional writer. Your job is to create well-written,
clear, and engaging content. Use the format_document tool to format your output."""

    model = ChatAnthropic(
        model="claude-3-5-sonnet-20241022",
        temperature=0.7
    ).bind_tools([format_document])

    messages = [SystemMessage(content=system_prompt)] + list(state["messages"])

    try:
        response = await model.ainvoke(messages)

        # Execute tool calls if present
        if hasattr(response, "tool_calls") and response.tool_calls:
            tool_results = []
            for tool_call in response.tool_calls:
                if tool_call["name"] == "format_document":
                    result = await format_document.ainvoke(tool_call["args"])
                    tool_results.append(result)

            final_response = AIMessage(
                content="\n".join(tool_results),
                name="writer"
            )
        else:
            response.name = "writer"
            final_response = response

        return {"messages": [final_response]}

    except Exception as e:
        error_message = AIMessage(
            content=f"Writing error: {str(e)}",
            name="writer"
        )
        return {"messages": [error_message]}


# ============================================================================
# Routing Logic
# ============================================================================

def route_to_agent(state: SupervisorState) -> str:
    """
    Route to the next agent based on supervisor decision.

    Args:
        state: Current state

    Returns:
        Name of the next agent to invoke
    """
    next_agent = state.get("next_agent", "FINISH")

    if next_agent == "FINISH":
        return END

    return next_agent


# ============================================================================
# Graph Construction
# ============================================================================

def create_graph() -> StateGraph:
    """
    Create and compile the multi-agent supervisor graph.

    Returns:
        Compiled StateGraph
    """
    workflow = StateGraph(SupervisorState)

    # Add all agent nodes
    workflow.add_node("supervisor", supervisor_node)
    workflow.add_node("researcher", researcher_node)
    workflow.add_node("calculator", calculator_node)
    workflow.add_node("writer", writer_node)

    # Define the flow
    # Start with supervisor
    workflow.add_edge(START, "supervisor")

    # Supervisor routes to agents
    workflow.add_conditional_edges(
        "supervisor",
        route_to_agent,
        {
            "researcher": "researcher",
            "calculator": "calculator",
            "writer": "writer",
            END: END
        }
    )

    # Agents return to supervisor
    workflow.add_edge("researcher", "supervisor")
    workflow.add_edge("calculator", "supervisor")
    workflow.add_edge("writer", "supervisor")

    # Add SQLite checkpointing
    checkpointer = SqliteSaver.from_conn_string("supervisor_checkpoints.db")

    # Compile the graph
    graph = workflow.compile(checkpointer=checkpointer)

    return graph


# ============================================================================
# Usage Example
# ============================================================================

async def main():
    """
    Example usage of the supervisor multi-agent system.
    """
    graph = create_graph()

    # Configuration
    config = {
        "configurable": {
            "thread_id": "supervisor-example-1"
        }
    }

    # Initial state
    initial_state = {
        "messages": [
            HumanMessage(content=(
                "I need help with a research project. "
                "First, search for information about LangGraph. "
                "Then calculate the sum of 123 and 456. "
                "Finally, write a short summary document."
            ))
        ],
        "next_agent": "",
        "agent_history": []
    }

    # Run the system
    print("Running multi-agent system...\n")

    result = await graph.ainvoke(initial_state, config)

    # Print the conversation
    print("=" * 80)
    print("CONVERSATION")
    print("=" * 80)
    for message in result["messages"]:
        name = getattr(message, "name", "Unknown")
        content = message.content
        print(f"\n[{name}]")
        print(content)
        print("-" * 80)

    # Print agent history
    print("\n" + "=" * 80)
    print("AGENT EXECUTION HISTORY")
    print("=" * 80)
    print(" â†’ ".join(result.get("agent_history", [])))


# ============================================================================
# CLI Entry Point
# ============================================================================

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
